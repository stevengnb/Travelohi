{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path & Declaration\n",
    "test_path = './dataset/test/'\n",
    "train_path = './dataset/train/'\n",
    "valid_path = './dataset/valid/'\n",
    "\n",
    "types = ['Brazil', 'Canada', 'Finland', 'Japan', 'United-Kingdom', 'United_States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "def process_data(path):\n",
    "    df = pd.read_csv(path + '_classes.csv')\n",
    "    result_img = []\n",
    "    result_idx = []\n",
    "    \n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            image_path = row['filename']\n",
    "            image = Image.open(path + image_path)\n",
    "            image = image.resize((224, 224)) \n",
    "            normalized_image = np.array(image) / 255.0\n",
    "            label_index = np.argmax(row.iloc[1:].values)\n",
    "            result_img.append(normalized_image)\n",
    "            result_idx.append(label_index)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    result_idx = to_categorical(result_idx, num_classes=7)\n",
    "    result_img = np.array(result_img, dtype=np.float32)\n",
    "    result_idx = np.array(result_idx, dtype=np.float32)\n",
    "\n",
    "    return tf.data.Dataset.from_tensor_slices((result_img, result_idx)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Data\n",
    "test_data = process_data(test_path)\n",
    "train_data = process_data(train_path)\n",
    "valid_data = process_data(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AlexNet Model\n",
    "def AlexNet():\n",
    "  inp = layers.Input((224, 224, 3))\n",
    "  x = layers.Conv2D(96, 11, 4, activation='relu')(inp)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Conv2D(256, 5, 1, activation='relu')(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
    "  x = layers.Conv2D(384, 3, 1, activation='relu')(x)\n",
    "  x = layers.Conv2D(256, 3, 1, activation='relu')(x)\n",
    "  x = layers.MaxPooling2D(3, 2)(x)\n",
    "  x = layers.Flatten()(x)\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  x = layers.Dense(4096, activation='relu')(x)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  x = layers.Dense(7, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=inp, outputs=x)\n",
    "\n",
    "  return model\n",
    "\n",
    "model = AlexNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compile\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385/385 [==============================] - 123s 318ms/step - loss: 1.2870 - accuracy: 0.5019 - val_loss: 1.7676 - val_accuracy: 0.3120 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "385/385 [==============================] - 124s 322ms/step - loss: 1.1533 - accuracy: 0.5526 - val_loss: 2.1390 - val_accuracy: 0.2766 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "385/385 [==============================] - 123s 320ms/step - loss: 0.9848 - accuracy: 0.6265 - val_loss: 2.2201 - val_accuracy: 0.3035 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "385/385 [==============================] - 130s 337ms/step - loss: 0.8292 - accuracy: 0.6939 - val_loss: 2.6735 - val_accuracy: 0.2811 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "385/385 [==============================] - 138s 359ms/step - loss: 0.7080 - accuracy: 0.7403 - val_loss: 2.4184 - val_accuracy: 0.3457 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "385/385 [==============================] - ETA: 0s - loss: 0.5803 - accuracy: 0.7870\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "385/385 [==============================] - 168s 436ms/step - loss: 0.5803 - accuracy: 0.7870 - val_loss: 2.4266 - val_accuracy: 0.3193 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "385/385 [==============================] - 160s 417ms/step - loss: 0.4608 - accuracy: 0.8405 - val_loss: 2.0882 - val_accuracy: 0.4058 - lr: 5.0000e-05\n",
      "Epoch 8/15\n",
      "385/385 [==============================] - 131s 341ms/step - loss: 0.2695 - accuracy: 0.9081 - val_loss: 2.4215 - val_accuracy: 0.3940 - lr: 5.0000e-05\n",
      "Epoch 9/15\n",
      "385/385 [==============================] - 131s 341ms/step - loss: 0.1683 - accuracy: 0.9422 - val_loss: 2.7671 - val_accuracy: 0.3985 - lr: 5.0000e-05\n",
      "Epoch 10/15\n",
      "385/385 [==============================] - 134s 347ms/step - loss: 0.1379 - accuracy: 0.9561 - val_loss: 3.1443 - val_accuracy: 0.3800 - lr: 5.0000e-05\n",
      "Epoch 11/15\n",
      "385/385 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.9595\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "385/385 [==============================] - 131s 339ms/step - loss: 0.1182 - accuracy: 0.9595 - val_loss: 3.7157 - val_accuracy: 0.3727 - lr: 5.0000e-05\n",
      "Epoch 12/15\n",
      "385/385 [==============================] - 150s 389ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 3.3875 - val_accuracy: 0.3918 - lr: 2.5000e-05\n",
      "Epoch 13/15\n",
      "385/385 [==============================] - 169s 440ms/step - loss: 0.0612 - accuracy: 0.9823 - val_loss: 3.8129 - val_accuracy: 0.3969 - lr: 2.5000e-05\n",
      "Epoch 14/15\n",
      "385/385 [==============================] - 127s 329ms/step - loss: 0.0350 - accuracy: 0.9922 - val_loss: 3.9638 - val_accuracy: 0.4103 - lr: 2.5000e-05\n",
      "Epoch 15/15\n",
      "385/385 [==============================] - 127s 329ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 3.7338 - val_accuracy: 0.4210 - lr: 2.5000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x205415d3220>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Fit\n",
    "es = ReduceLROnPlateau(monitor='val_loss', patience = 5, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "    \n",
    "model.fit(train_data, batch_size=24, epochs=15, validation_data=valid_data,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
